<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Back Home AR Experience — Stable</title>

  <script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1.6.0/dist/aframe-master.min.js"></script>
  <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

  <style>
    body { margin: 0; overflow: hidden; font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; }
    .loader {
      position: absolute; inset: 0; display: flex; align-items: center; justify-content: center;
      background: rgba(0,0,0,0.85); color: #fff; z-index: 9999;
    }
    .gate {
      position: absolute; inset: 0; display: flex; align-items: center; justify-content: center;
      z-index: 10000; background: rgba(0,0,0,0.55); color: #fff; text-align: center; padding: 24px;
    }
    .gate[hidden] { display: none; }
    .btn { margin-top: 12px; background: #4caf50; color: #fff; border: 0; border-radius: 20px; padding: 10px 18px; font-weight: 700; cursor: pointer; }
    .debug { position: absolute; top: 8px; left: 8px; z-index: 10001; background: rgba(0,0,0,0.75); color:#fff; padding:6px 8px; border-radius:6px; font-size:12px; }
  </style>

  <script>
    // Platform flags (if you need them later)
    const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
    const isAndroid = /Android/i.test(navigator.userAgent);

    // No frustum culling (keep the plane rendered even if bounding box jitters)
    AFRAME.registerComponent('no-frustum-cull', {
      init() {
        this.el.addEventListener('object3dset', () => {
          const obj = this.el.getObject3D('mesh') || this.el.object3D;
          if (obj) obj.traverse(n => n.frustumCulled = false);
        });
        const obj = this.el.getObject3D('mesh') || this.el.object3D;
        if (obj) obj.traverse(n => n.frustumCulled = false);
      }
    });

    // Auto-fit plane to color video aspect
    AFRAME.registerComponent('fit-video-plane', {
      schema: { target: {type: 'selector'}, baseWidth: {default: 300} },
      init() {
        const plane = this.el;
        const video = this.data.target;
        if (!video) return;
        const setSize = () => {
          const w = video.videoWidth || 16, h = video.videoHeight || 9;
          const aspect = w / h;
          plane.setAttribute('geometry', `primitive: plane; width: ${this.data.baseWidth}; height: ${this.data.baseWidth / aspect}`);
        };
        video.addEventListener('loadedmetadata', setSize);
        if (video.readyState >= 1) setSize();
      }
    });

    // Pose smoother (position + rotation). Runs on the content (child of a-nft)
    AFRAME.registerComponent('pose-smoother', {
      schema: { pos: {default: 0.18}, rot: {default: 0.18} }, // 0..1 (higher = faster)
      init() {
        const o = this.el.object3D;
        this._p = o.position.clone();
        this._q = o.quaternion.clone();
      },
      tick() {
        const o = this.el.object3D;
        // Lerp position
        this._p.lerp(o.position, this.data.pos);
        o.position.copy(this._p);
        // Slerp rotation
        this._q.slerp(o.quaternion, this.data.rot);
        o.quaternion.copy(this._q);
      }
    });

    // Stable videoplayer with FOUND/LOST hysteresis + confirm window
    AFRAME.registerComponent('stable-videoplayer', {
      schema: {
        confirmMs: {default: 180},   // Require this much time of "found" before we declare locked
        lostGraceMs: {default: 900}  // Keep showing/playing for this time after 'markerLost'
      },
      init() {
        const debug = (m) => { const d = document.getElementById('debug'); if (d) d.textContent = m; };

        const videoColor = document.querySelector('#videoColor');
        const videoAlpha = document.querySelector('#videoAlpha');
        const gate = document.getElementById('gate');
        const btn = document.getElementById('enableBtn');

        // Start fully muted so we can prime decoding; audio is armed by user
        videoColor.setAttribute('muted', ''); videoColor.muted = true; videoColor.volume = 0;
        videoAlpha.setAttribute('muted', ''); videoAlpha.muted = true; videoAlpha.volume = 0;

        let audioArmed = false;   // set by one user tap
        let locked = false;       // we consider tracking solid (after confirmMs)
        let lostTimer = null;     // hysteresis timer after markerLost
        let confirmTimer = null;  // confirmation window after markerFound

        const armAudio = async () => {
          try {
            // Prime both videos (muted) so unmute is instant when locked
            await Promise.allSettled([ videoColor.play(), videoAlpha.play() ]);
            videoColor.muted = true; videoColor.volume = 0;
            audioArmed = true;
            gate.hidden = true;
            debug('Audio armed. Waiting for stable lock…');
          } catch(e) {
            debug('Tap again to arm audio');
            console.warn('Arming error:', e);
          }
        };
        btn.addEventListener('click', armAudio, { once: true });

        const onStableLock = async () => {
          if (!audioArmed || !videoColor) return;
          try {
            videoColor.muted = false; videoColor.volume = 1.0;
            await videoColor.play();
            debug('Stable lock — audio ON');
          } catch(e) {
            debug('Tap to enable audio');
            gate.hidden = false;
            console.warn('Unmute error:', e);
          }
        };

        // --- Marker events with hysteresis ---
        this.el.addEventListener('markerFound', () => {
          debug('Marker found (confirming…)');
          // cancel any pending "lost"
          if (lostTimer) { clearTimeout(lostTimer); lostTimer = null; }

          // Ensure frames are flowing (muted)
          if (videoColor.paused) videoColor.play().catch(()=>{});
          if (videoAlpha.paused) videoAlpha.play().catch(()=>{});

          // Start (or restart) a short confirmation timer; only after it elapses we "lock"
          if (confirmTimer) clearTimeout(confirmTimer);
          confirmTimer = setTimeout(() => {
            if (!locked) {
              locked = true;
              onStableLock();
            }
          }, this.data.confirmMs);
        });

        this.el.addEventListener('markerLost', () => {
          debug('Marker lost (grace period…)');
          // If we were in confirmation, cancel it
          if (confirmTimer) { clearTimeout(confirmTimer); confirmTimer = null; }

          // Start grace timer; if we refind within grace, nothing happens
          if (lostTimer) clearTimeout(lostTimer);
          lostTimer = setTimeout(() => {
            // After grace expires, consider fully lost
            locked = false;
            // Stop & remute so next stable lock restarts cleanly
            videoColor.muted = true; videoColor.volume = 0;
            if (!videoColor.paused) videoColor.pause();
            if (!videoAlpha.paused) videoAlpha.pause();
            debug('Lost after grace — audio OFF, paused');
          }, this.data.lostGraceMs);
        });

        // Show the arm gate once (required for iOS/Android audio policies)
        gate.hidden = false;
      }
    });

    // Loader hide (robust): listen to several events + a timeout
    document.addEventListener('DOMContentLoaded', () => {
      const loader = document.getElementById('loader');
      const scene  = document.querySelector('a-scene');
      if (!loader || !scene) return;

      const hide = (why) => {
        if (loader.style.display === 'none') return;
        loader.style.display = 'none';
        console.log('Hide loader:', why);
      };

      scene.addEventListener('loaded',       () => hide('scene loaded'));
      scene.addEventListener('renderstart',  () => hide('renderstart'));
      scene.addEventListener('arReady',      () => hide('arReady'));
      scene.addEventListener('camera-init',  () => hide('camera-init'));
      window.addEventListener('arjs-video-loaded', () => hide('arjs-video-loaded'));
      scene.addEventListener('markerFound',  () => hide('markerFound'));
      setTimeout(() => hide('timeout fallback'), 7000);
    });
  </script>
</head>

<body style="margin: 0; overflow: hidden;">
  <div class="loader" id="loader"><div>Loading, please wait…</div></div>

  <!-- One explicit gesture to arm audio (no sound yet). Sound begins on stable lock. -->
  <div class="gate" id="gate" hidden>
    <div>
      <div>Tap once to arm audio. Sound will start when the image is stably detected.</div>
      <button class="btn" id="enableBtn">Arm Audio</button>
    </div>
  </div>
  <div class="debug" id="debug">Init…</div>

  <a-scene
    vr-mode-ui="enabled: false;"
    renderer="antialias: true; logarithmicDepthBuffer: true; precision: high;"
    embedded
    arjs="sourceType: webcam; trackingMethod: best; debugUIEnabled: false; maxDetectionRate: 60; canvasWidth: 1280; canvasHeight: 960;"
  >
    <a-assets timeout="3000">
      <!-- Keep muted; audio is armed and starts only on stable marker -->
      <video
        id="videoColor"
        src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Color.mp4"
        preload="metadata"
        loop
        muted
        crossorigin="anonymous"
        webkit-playsinline
        playsinline
      ></video>

      <video
        id="videoAlpha"
        src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Alpha.mp4"
        preload="metadata"
        loop
        muted
        crossorigin="anonymous"
        webkit-playsinline
        playsinline
      ></video>
    </a-assets>

    <!-- Transparency matte shader -->
    <script id="matte-shader" type="x-shader/x-fragment">
      precision mediump float;
      uniform sampler2D videoColor;
      uniform sampler2D videoAlpha;
      varying vec2 vUV;
      void main() {
        vec4 color = texture2D(videoColor, vUV);
        vec4 alpha = texture2D(videoAlpha, vUV);
        gl_FragColor = vec4(color.rgb, alpha.r);
      }
    </script>

    <script>
      AFRAME.registerShader('video-matte-shader', {
        schema: {
          videoColor: { type: 'map', is: 'uniform' },
          videoAlpha: { type: 'map', is: 'uniform' }
        },
        fragmentShader: document.getElementById('matte-shader').textContent,
        vertexShader: `
          varying vec2 vUV;
          void main() {
            vUV = uv;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
          }
        `
      });
    </script>

    <!-- IMPORTANT: url points to the NFT dataset ROOT (no extension) -->
    <a-nft
      stable-videoplayer="confirmMs: 180; lostGraceMs: 900"
      type="nft"
      url="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Image-tracker_Crab"
      smooth="true"
      smoothCount="30"
      smoothTolerance="0.01"
      smoothThreshold="10"
    >
      <a-entity id="videoPlane"
        no-frustum-cull
        fit-video-plane="target: #videoColor; baseWidth: 300"
        pose-smoother="pos: 0.18; rot: 0.18"
        geometry="primitive: plane; width: 300; height: 150"
        material="shader: video-matte-shader;
                  videoColor: #videoColor;
                  videoAlpha: #videoAlpha;
                  transparent: true;"
        position="0 0 0.1"
        rotation="-90 0 0"
      ></a-entity>
    </a-nft>

    <a-entity camera look-controls position="0 1.6 0"></a-entity>
  </a-scene>
</body>
</html>
