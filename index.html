<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Back Home AR</title>
  
  <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script>
  
  <style>
    html, body { 
      margin: 0; 
      height: 100%; 
      overflow: hidden; 
      font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
    }
    
    #loader {
      position: fixed; 
      top: 0; 
      left: 0; 
      width: 100%; 
      height: 100%; 
      background: rgba(0,0,0,0.85); 
      color: #fff; 
      display: flex; 
      align-items: center; 
      justify-content: center; 
      z-index: 1000;
      font-size: 18px;
    }
    
    #tapOverlay {
      position: fixed; 
      top: 0; 
      left: 0; 
      width: 100%; 
      height: 100%; 
      background: rgba(0,0,0,0.7); 
      color: #fff; 
      display: none; 
      align-items: center; 
      justify-content: center; 
      text-align: center; 
      z-index: 1001;
    }
    
    #tapOverlay button {
      margin-top: 20px; 
      padding: 15px 25px; 
      border: 0; 
      border-radius: 8px; 
      color: #fff; 
      background: #1976d2; 
      font-weight: bold; 
      font-size: 16px;
      cursor: pointer;
    }
    
    .hidden { 
      display: none !important; 
    }

    #reticle {
      position: absolute;
      top: 50%;
      left: 50%;
      width: 40px;
      height: 40px;
      border: 2px solid #fff;
      border-radius: 50%;
      transform: translate(-50%, -50%);
      pointer-events: none;
      z-index: 100;
      display: none;
    }
  </style>

  <script id="matte-shader" type="x-shader/x-fragment">
    precision mediump float;
    uniform sampler2D videoColor;
    uniform sampler2D videoAlpha;
    uniform float opacity;
    varying vec2 vUV;
    
    void main() {
      vec4 color = texture2D(videoColor, vUV);
      float alpha = texture2D(videoAlpha, vUV).r * opacity;
      gl_FragColor = vec4(color.rgb, alpha);
    }
  </script>
</head>

<body>
  <div id="loader">
    <div>Loading AR Experience...</div>
  </div>

  <div id="tapOverlay">
    <div>
      <div style="font-size: 20px; margin-bottom: 10px;">AR Experience Ready</div>
      <div style="margin-bottom: 20px;">Tap to start</div>
      <button id="tapBtn">Start AR</button>
    </div>
  </div>

  <div id="reticle"></div>

  <a-scene
    renderer="antialias: true; precision: medium; alpha: true; colorManagement: true;"
    background="transparent: true"
    webxr="requiredFeatures: hit-test;"
    vr-mode-ui="enabled: false"
  >
    <a-assets>
      <video id="videoColor"
             src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Color.mp4"
             preload="auto" 
             loop 
             muted 
             crossorigin="anonymous" 
             playsinline 
             webkit-playsinline>
      </video>
      <video id="videoAlpha"
             src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Alpha.mp4"
             preload="auto" 
             loop 
             muted 
             crossorigin="anonymous" 
             playsinline 
             webkit-playsinline>
      </video>
    </a-assets>

    <a-plane
      id="videoPlane"
      width="0.85"
      height="0.67"
      material="shader: video-matte; videoColor: #videoColor; videoAlpha: #videoAlpha; transparent: true; opacity: 1.0"
      visible="false"
    ></a-plane>

    <a-camera wasd-controls="enabled: false"></a-camera>
  </a-scene>

  <script>
    // Register the video-matte shader
    AFRAME.registerShader('video-matte', {
      schema: {
        videoColor: { type: 'map', is: 'uniform' },
        videoAlpha: { type: 'map', is: 'uniform' },
        opacity: { type: 'number', default: 1.0, is: 'uniform' }
      },
      fragmentShader: document.getElementById('matte-shader').textContent,
      vertexShader: `
        varying vec2 vUV;
        void main() {
          vUV = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
      `
    });
    
    document.addEventListener('DOMContentLoaded', function() {
      const scene = document.querySelector('a-scene');
      const loader = document.getElementById('loader');
      const tapOverlay = document.getElementById('tapOverlay');
      const tapBtn = document.getElementById('tapBtn');
      const reticle = document.getElementById('reticle');
      const videoPlane = document.getElementById('videoPlane');
      const videoColor = document.getElementById('videoColor');
      const videoAlpha = document.getElementById('videoAlpha');
      
      let placed = false;
      let hitTestSource = null;
      let refSpace = null;
      
      function showStartUI() {
        loader.classList.add('hidden');
        tapOverlay.style.display = 'flex';
      }
      
      if (scene.hasLoaded) {
        showStartUI();
      } else {
        scene.addEventListener('loaded', showStartUI);
      }
      
      // The "Start AR" button click must directly trigger the enterVR() call
      // This user gesture is required to activate the camera permission prompt on iOS
      tapBtn.addEventListener('click', function() {
        scene.enterVR();
      });

      // After the user accepts the AR session, hide the overlay and show the reticle
      scene.addEventListener('enter-vr', () => {
        if (scene.is('ar-mode')) {
          tapOverlay.classList.add('hidden');
          reticle.style.display = 'block';
        }
      });
      
      function placeContent() {
        placed = true;
        reticle.style.display = 'none';
        videoPlane.setAttribute('visible', true);
        
        // Unmute and play videos
        videoColor.muted = false;
        videoColor.volume = 0.8;
        videoColor.play();
        videoAlpha.play();
      }
      
      // Use a screen tap to place the content
      window.addEventListener('click', function() {
        // Place content only if we are in an active AR session and it hasn't been placed yet
        if (scene.is('ar-mode') && !placed && hitTestSource) {
          placeContent();
        }
      });
      
      const xr = scene.renderer.xr;
      
      xr.addEventListener('sessionstart', async function() {
        const session = xr.getSession();
        refSpace = await session.requestReferenceSpace('local');
        const viewerSpace = await session.requestReferenceSpace('viewer');
        hitTestSource = await session.requestHitTestSource({ space: viewerSpace });
      });
      
      xr.addEventListener('sessionend', function() {
        hitTestSource = null;
        refSpace = null;
        placed = false;
        videoColor.pause();
        videoAlpha.pause();
        videoPlane.setAttribute('visible', false);
        reticle.style.display = 'none';
      });
      
      // Render loop to update the video plane's position using hit-testing
      scene.renderer.setAnimationLoop(function(time, frame) {
        if (!frame || !hitTestSource || !refSpace || placed) return;
        
        const hitTestResults = frame.getHitTestResults(hitTestSource);
        if (hitTestResults.length > 0) {
          const hit = hitTestResults[0];
          const pose = hit.getPose(refSpace);
          
          if (pose) {
            // Use the hit-test pose to position and orient the video plane
            videoPlane.object3D.position.copy(pose.transform.position);
            videoPlane.object3D.quaternion.copy(pose.transform.orientation);
          }
        }
      });
    });
  </script>
</body>
</html>