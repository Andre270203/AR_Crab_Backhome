<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>Back Home AR Experience</title>

  <script src="https://cdn.jsdelivr.net/gh/aframevr/aframe@1.6.0/dist/aframe-master.min.js"></script>
  <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script>

  <style>
    body { margin: 0; overflow: hidden; font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif; }
    .arjs-loader {
      position: absolute; inset: 0; display: flex; align-items: center; justify-content: center;
      background: rgba(0,0,0,0.85); color: #fff; z-index: 9999;
    }
    .gate {
      position: absolute; inset: 0; display: flex; align-items: center; justify-content: center;
      z-index: 10000; background: rgba(0,0,0,0.55); color: #fff; text-align: center; padding: 24px;
    }
    .gate[hidden] { display: none; }
    .btn {
      margin-top: 12px; background: #4caf50; color: #fff; border: 0; border-radius: 20px; padding: 10px 18px; font-weight: 700; cursor: pointer;
    }
    .debug { position: absolute; top: 8px; left: 8px; z-index: 10001; background: rgba(0,0,0,0.75); color:#fff; padding:6px 8px; border-radius:6px; font-size:12px; }
  </style>

  <script>
    const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
    const isAndroid = /Android/i.test(navigator.userAgent);

    // Auto-fit the plane to the color video aspect ratio
    AFRAME.registerComponent('fit-video-plane', {
      schema: { target: {type: 'selector'}, baseWidth: {default: 300} },
      init() {
        const plane = this.el;
        const video = this.data.target;
        if (!video) return;
        const setSize = () => {
          const w = video.videoWidth || 16, h = video.videoHeight || 9;
          const aspect = w / h;
          plane.setAttribute('geometry', `primitive: plane; width: ${this.data.baseWidth}; height: ${this.data.baseWidth / aspect}`);
        };
        video.addEventListener('loadedmetadata', setSize);
        if (video.readyState >= 1) setSize();
      }
    });

    // Enhanced content stabilizer with smooth position interpolation
    AFRAME.registerComponent('stabilize', {
      schema: { 
        factor: {default: 0.15},
        smoothing: {default: true}
      },
      init() {
        this.isTracking = false;
        this.targetPosition = { x: 0, y: 0, z: 0 };
        this.currentPosition = { x: 0, y: 0, z: 0 };
        this.smoothingFactor = this.data.factor;
        
        // Listen for marker events to control tracking state
        const marker = this.el.closest('a-nft');
        if (marker) {
          marker.addEventListener('markerFound', () => {
            this.isTracking = true;
            this.startInterpolation();
          });
          
          marker.addEventListener('markerLost', () => {
            // Don't immediately stop tracking - use buffer
            setTimeout(() => {
              this.isTracking = false;
            }, 500); // 500ms stability buffer
          });
        }
      },
      
      tick() {
        if (!this.data.smoothing) {
          // Original simple stabilization
          const p = this.el.object3D.position;
          if (!this.prev) this.prev = p.clone();
          this.prev.lerp(p, this.data.factor);
          this.el.object3D.position.copy(this.prev);
        }
      },
      
      startInterpolation() {
        if (!this.data.smoothing || !this.isTracking) return;
        
        const interpolate = () => {
          if (this.isTracking) {
            const currentPos = this.el.object3D.position;
            
            // Update target position from current transform
            this.targetPosition.x = currentPos.x;
            this.targetPosition.y = currentPos.y;
            this.targetPosition.z = currentPos.z;
            
            // Smooth interpolation
            this.currentPosition.x += (this.targetPosition.x - this.currentPosition.x) * this.smoothingFactor;
            this.currentPosition.y += (this.targetPosition.y - this.currentPosition.y) * this.smoothingFactor;
            this.currentPosition.z += (this.targetPosition.z - this.currentPosition.z) * this.smoothingFactor;
            
            // Apply smoothed position
            this.el.object3D.position.set(
              this.currentPosition.x,
              this.currentPosition.y,
              this.currentPosition.z
            );
            
            requestAnimationFrame(interpolate);
          }
        };
        
        interpolate();
      }
    });

    // Enhanced videoplayer with stability features and improved audio handling
    AFRAME.registerComponent('videoplayer', {
      init: function () {
        const debug = (msg) => { 
          const d = document.getElementById('debug'); 
          if (d) d.textContent = msg;
          console.log(`Platform: ${isIOS ? 'iOS' : isAndroid ? 'Android' : 'Desktop'} - ${msg}`);
        };

        const videoColor = document.querySelector('#videoColor');
        const videoAlpha = document.querySelector('#videoAlpha');
        const gate = document.getElementById('gate');
        const btn = document.getElementById('enableBtn');

        // Stability variables
        let isTracking = false;
        let stabilityTimer = null;
        let lastMarkerTime = 0;
        let hasUserInteracted = false;

        // Start fully muted to satisfy autoplay rules
        videoColor.setAttribute('muted', ''); videoColor.muted = true; videoColor.volume = 0;
        videoAlpha.setAttribute('muted', ''); videoAlpha.muted = true; videoAlpha.volume = 0;

        let audioArmed = false;   // set to true after the ONE user gesture
        let audioLive  = false;   // true while marker is found & color is unmuted

        // Enhanced play function with platform-specific optimizations
        const playVideos = () => {
          debug('Attempting to play videos...');
          try {
            if (videoColor && videoColor.paused) {
              if (hasUserInteracted || isAndroid) {
                videoColor.muted = false;
                videoColor.volume = 1.0;
              }
              
              const playPromise1 = videoColor.play();
              if (playPromise1 !== undefined) {
                playPromise1.then(() => {
                  debug(`Color video playing ${videoColor.muted ? 'muted' : 'with sound'}`);
                }).catch(error => {
                  console.error('Color video play failed:', error);
                  if (isIOS && !videoColor.muted) {
                    videoColor.muted = true;
                    videoColor.play().then(() => {
                      debug('Color video playing muted (fallback)');
                    });
                  }
                });
              }
            }
            
            if (videoAlpha && videoAlpha.paused) {
              const playPromise2 = videoAlpha.play();
              if (playPromise2 !== undefined) {
                playPromise2.then(() => {
                  debug('Alpha video playing');
                }).catch(error => {
                  console.error('Alpha video play failed:', error);
                });
              }
            }
          } catch (error) {
            console.error('Error playing videos:', error);
          }
        };

        // One explicit gesture to "arm" audio (no sound yet)
        const armAudio = async () => {
          try {
            hasUserInteracted = true;
            // Prime decoding so unmute on detection is instant
            await Promise.allSettled([ videoColor.play(), videoAlpha.play() ]);
            // Keep muted until the marker is detected
            videoColor.muted = true;  videoColor.volume = 0;
            audioArmed = true;
            gate.hidden = true;
            debug('Audio armed. Waiting for marker…');
          } catch (e) {
            debug('Tap again to arm audio');
            console.warn('Arming error:', e);
          }
        };
        btn.addEventListener('click', armAudio, { once: true });

        // iOS-specific interaction handling
        if (isIOS) {
          const enableInteraction = () => {
            if (!hasUserInteracted) {
              hasUserInteracted = true;
              debug('iOS: User interaction detected');
              if (isTracking) playVideos();
            }
          };
          document.addEventListener('touchstart', enableInteraction, { once: true });
          document.addEventListener('click', enableInteraction, { once: true });
        }

        // Android autoplay attempt
        if (isAndroid) {
          setTimeout(() => {
            if (!hasUserInteracted) {
              debug('Android: Attempting autoplay');
              hasUserInteracted = true;
              if (isTracking) playVideos();
            }
          }, 1000);
        }

        // Enhanced marker found with stability features
        this.el.addEventListener('markerFound', async () => {
          debug('Marker found');
          isTracking = true;
          lastMarkerTime = Date.now();
          
          // Clear any stability timeout
          if (stabilityTimer) {
            clearTimeout(stabilityTimer);
            stabilityTimer = null;
          }

          // Make sure frames are flowing
          if (videoColor.paused) videoColor.play().catch(()=>{});
          if (videoAlpha.paused) videoAlpha.play().catch(()=>{});

          // If armed, start audio NOW (unmute exactly on detection)
          if (audioArmed && !audioLive) {
            try {
              videoColor.muted = false; videoColor.volume = 1.0;
              await videoColor.play();
              audioLive = true;
              debug('Marker found — audio started');
            } catch (e) {
              // If browser still refuses, leave gate visible to try again
              audioLive = false;
              gate.hidden = false;
              debug('Tap to enable audio');
              console.warn('Unmute-on-detect error:', e);
            }
          } else if (hasUserInteracted || isAndroid) {
            playVideos();
          } else if (isIOS) {
            gate.hidden = false;
            debug('Tap anywhere to enable video playback');
          }
        });

        // Enhanced marker lost with stability buffer
        this.el.addEventListener('markerLost', () => {
          debug('Marker lost');
          
          // Add stability buffer - don't immediately stop tracking
          stabilityTimer = setTimeout(() => {
            isTracking = false;
            audioLive = false;
            
            // Stop everything and re-mute so the next detection starts fresh
            videoColor.muted = true; videoColor.volume = 0;
            if (!videoColor.paused) videoColor.pause();
            if (!videoAlpha.paused) videoAlpha.pause();
            
            debug('Tracking stopped after stability buffer');
          }, 500); // 500ms buffer before stopping
        });

        // Show the gate for one clean gesture on any platform
        gate.hidden = false;
        debug(`Platform detected: ${isIOS ? 'iOS' : isAndroid ? 'Android' : 'Desktop'}`);
      }
    });
  </script>
</head>

<body style="margin: 0; overflow: hidden;">
  <div class="arjs-loader" id="loader"><div>Loading, please wait…</div></div>

  <!-- One clear gesture to "arm" audio (no sound yet). Sound begins on marker detection. -->
  <div class="gate" id="gate" hidden>
    <div>
      <div>Tap once to arm audio. Sound will start when the image is detected.</div>
      <button class="btn" id="enableBtn">Arm Audio</button>
    </div>
  </div>
  <div class="debug" id="debug">Init…</div>

  <a-scene
    vr-mode-ui="enabled: false;"
    renderer="logarithmicDepthBuffer: true; precision: medium;"
    embedded
    arjs="sourceType: webcam; trackingMethod: best; debugUIEnabled: false;"
    onloaded="document.getElementById('loader').style.display='none';"
  >
    <a-assets>
      <!-- Keep muted; we unmute the color track exactly on markerFound -->
      <video
        id="videoColor"
        src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Color.mp4"
        preload="metadata"
        loop
        muted
        crossorigin="anonymous"
        webkit-playsinline
        playsinline
      ></video>

      <video
        id="videoAlpha"
        src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Alpha.mp4"
        preload="metadata"
        loop
        muted
        crossorigin="anonymous"
        webkit-playsinline
        playsinline
      ></video>
    </a-assets>

    <!-- Transparency matte shader -->
    <script id="matte-shader" type="x-shader/x-fragment">
      precision mediump float;
      uniform sampler2D videoColor;
      uniform sampler2D videoAlpha;
      varying vec2 vUV;
      void main() {
        vec4 color = texture2D(videoColor, vUV);
        vec4 alpha = texture2D(videoAlpha, vUV);
        gl_FragColor = vec4(color.rgb, alpha.r);
      }
    </script>

    <script>
      AFRAME.registerShader('video-matte-shader', {
        schema: {
          videoColor: { type: 'map', is: 'uniform' },
          videoAlpha: { type: 'map', is: 'uniform' }
        },
        fragmentShader: document.getElementById('matte-shader').textContent,
        vertexShader: `
          varying vec2 vUV;
          void main() {
            vUV = uv;
            gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
          }
        `
      });
    </script>

    <!-- NFT marker with enhanced smoothing and stability -->
    <a-nft
      videoplayer
      type="nft"
      url="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/marker/AR_Image-tracker_Crab"
      smooth="true"
      smoothCount="15"
      smoothTolerance="0.005"
      smoothThreshold="3"
    >
      <!-- Plane: auto-fit to color video aspect; enhanced stabilizer for maximum smoothness -->
      <a-entity id="videoPlane"
        fit-video-plane="target: #videoColor; baseWidth: 225"
        stabilize="factor: 0.15; smoothing: true"
        geometry="primitive: plane; width: 225; height: 112.5"
        material="shader: video-matte-shader;
                  videoColor: #videoColor;
                  videoAlpha: #videoAlpha;
                  transparent: true;"
        position="0 0 0.1"
        rotation="-90 0 0"
      ></a-entity>
    </a-nft>

    <a-entity camera look-controls position="0 1.6 0"></a-entity>
  </a-scene>
</body>
</html>