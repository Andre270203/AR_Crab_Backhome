<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>Back Home AR â€” WebXR Hit-Test + Real Camera</title>

  <!-- A-Frame -->
  <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover" />

  <style>
    html, body { margin: 0; height: 100%; overflow: hidden; background: transparent; }
    /* Make sure the WebGL canvas doesn't paint a color */
    canvas.a-canvas { background: transparent !important; }

    /* Minimal UI; keep it non-blocking during AR */
    #ui {
      position: fixed; inset: 0;
      display: grid; place-items: center;
      pointer-events: none;   /* don't block AR taps */
      z-index: 10; color: #fff; font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
    }
    #startBtn {
      pointer-events: auto;   /* clickable */
      background: #1976d2; color: #fff; border: 0; border-radius: 10px;
      padding: 14px 20px; font-weight: 700; font-size: 16px;
      box-shadow: 0 6px 16px rgba(0,0,0,.25);
    }
    #tip {
      margin-top: 10px; font-size: 14px; opacity: .85; text-align: center;
    }
    .hidden { display: none !important; }
  </style>

  <!-- Fragment shader for video + alpha compositing -->
  <script id="matte-shader" type="x-shader/x-fragment">
    precision mediump float;
    uniform sampler2D videoColor;
    uniform sampler2D videoAlpha;
    uniform float opacity;
    varying vec2 vUV;
    void main() {
      vec4 color = texture2D(videoColor, vUV);
      float alpha = texture2D(videoAlpha, vUV).r * opacity;
      gl_FragColor = vec4(color.rgb, alpha);
    }
  </script>
</head>

<body>
  <!-- Lightweight UI (used to unlock audio and enter AR). Lives above canvas but doesn't block taps after start -->
  <div id="ui">
    <div id="panel">
      <button id="startBtn">Start AR</button>
      <div id="tip">Move phone to find a surface, then tap to place</div>
    </div>
  </div>

  <a-scene
    embedded
    vr-mode-ui="enabled: false"
    renderer="alpha: true; antialias: true; precision: medium"
    webxr="mode: ar; requiredFeatures: hit-test; optionalFeatures: dom-overlay; overlayElement: #ui"
  >
    <a-assets>
      <video id="videoColor"
             src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Color.mp4"
             preload="auto" loop muted crossorigin="anonymous" playsinline webkit-playsinline></video>
      <video id="videoAlpha"
             src="https://raw.githack.com/alevalve/AR_Crab_Backhome/main/AR_Video02_Alpha.mp4"
             preload="auto" loop muted crossorigin="anonymous" playsinline webkit-playsinline></video>
    </a-assets>

    <!-- Reticle that follows the hit-test result -->
    <a-entity id="reticle" visible="false">
      <a-ring radius-inner="0.045" radius-outer="0.055" rotation="-90 0 0" material="side: double"></a-ring>
      <a-entity position="0 0 0">
        <a-triangle scale="0.06 0.06 0.06" position="0.09 0 0" rotation="-90 0 0"></a-triangle>
      </a-entity>
    </a-entity>

    <!-- Video plane (hidden until placed) -->
    <a-plane
      id="videoPlane"
      visible="false"
      width="1.2"
      height="0.67"
      material="shader: video-matte; videoColor: #videoColor; videoAlpha: #videoAlpha; transparent: true; alphaTest: 0.001; opacity: 1"
    ></a-plane>

    <a-camera wasd-controls="enabled: false"></a-camera>
  </a-scene>

  <script>
    // Register the matte shader
    AFRAME.registerShader('video-matte', {
      schema: {
        videoColor: { type: 'map', is: 'uniform' },
        videoAlpha: { type: 'map', is: 'uniform' },
        opacity:    { type: 'number', default: 1.0, is: 'uniform' }
      },
      fragmentShader: document.getElementById('matte-shader').textContent,
      vertexShader: `
        varying vec2 vUV;
        void main() {
          vUV = uv;
          gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
        }
      `
    });

    (function () {
      const scene      = document.querySelector('a-scene');
      const startBtn   = document.getElementById('startBtn');
      const panel      = document.getElementById('panel');
      const reticleEl  = document.getElementById('reticle');
      const videoPlane = document.getElementById('videoPlane');

      const videoColor = document.getElementById('videoColor');
      const videoAlpha = document.getElementById('videoAlpha');

      let audioUnlocked = false;
      let placed = false;
      let hitTestSource = null;
      let refSpace = null;

      function ensureTransparentClear() {
        if (scene.renderer) scene.renderer.setClearColor(0x000000, 0);
      }

      function enterAR() {
        // A-Frame will request an immersive-ar session when entering "VR" here.
        scene.enterVR();
      }

      // Start AR & unlock audio (user gesture)
      startBtn.addEventListener('click', async () => {
        audioUnlocked = true;
        // Optionally pre-warm play in muted mode to satisfy autoplay, then pause until placed
        try {
          videoColor.muted = true; videoAlpha.muted = true;
          await Promise.allSettled([videoColor.play(), videoAlpha.play()]);
          videoColor.pause(); videoAlpha.pause();
        } catch (e) {}
        // Hide the panel but keep #ui for dom-overlay (pointer-events none anyway)
        panel.classList.add('hidden');
        enterAR();
      });

      // Once the scene is ready, enforce transparent clear
      if (scene.hasLoaded) ensureTransparentClear();
      else scene.addEventListener('loaded', ensureTransparentClear);

      // WebXR session events via three.js XR manager
      scene.renderer.xr.addEventListener('sessionstart', async () => {
        ensureTransparentClear();

        const session = scene.renderer.xr.getSession();
        // Reference spaces
        refSpace = await session.requestReferenceSpace('local');
        const viewerSpace = await session.requestReferenceSpace('viewer');

        // Hit test source
        hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

        // Show the reticle while we look for surfaces
        reticleEl.setAttribute('visible', true);
      });

      scene.renderer.xr.addEventListener('sessionend', () => {
        hitTestSource = null;
        refSpace = null;
        placed = false;
        reticleEl.setAttribute('visible', false);
        videoPlane.setAttribute('visible', false);
        videoColor.pause(); videoAlpha.pause();
      });

      // Per-frame: update reticle from hit-test
      scene.renderer.setAnimationLoop((time, frame) => {
        if (!frame || !hitTestSource || !refSpace) return;

        // Only keep reticle visible while content not placed
        if (placed) {
          reticleEl.setAttribute('visible', false);
          return;
        }

        const results = frame.getHitTestResults(hitTestSource);
        if (results.length > 0) {
          const hit = results[0];
          const pose = hit.getPose(refSpace);
          if (pose) {
            const { x, y, z } = pose.transform.position;
            const q = pose.transform.orientation;

            // Position the reticle on the hit surface, align with surface orientation
            reticleEl.object3D.position.set(x, y, z);
            reticleEl.object3D.quaternion.set(q.x, q.y, q.z, q.w);
            reticleEl.setAttribute('visible', true);
          }
        } else {
          reticleEl.setAttribute('visible', false);
        }
      });

      // Tap to place the content on current reticle pose
      window.addEventListener('click', async () => {
        // Only respond to taps while in AR, with a valid reticle, and not yet placed
        const inXR = scene.renderer.xr.isPresenting;
        if (!inXR || placed || reticleEl.getAttribute('visible') === false) return;

        placed = true;

        // Snap the plane to reticle pose and orient it to face the user a bit
        const pos = reticleEl.object3D.position.clone();
        const rot = reticleEl.object3D.rotation.clone();

        videoPlane.object3D.position.copy(pos);
        // Keep plane upright on the surface (use reticle's yaw, zero pitch/roll)
        videoPlane.object3D.rotation.set(-Math.PI / 2, rot.y, 0);

        videoPlane.setAttribute('visible', true);

        // Unmute color video if user unlocked audio
        if (audioUnlocked) {
          videoColor.muted = false;
          videoColor.volume = 0.8;
        } else {
          videoColor.muted = true;
        }

        try {
          await Promise.all([videoAlpha.play(), videoColor.play()]);
        } catch (e) {
          // If blocked, the next tap will try again
          console.warn('Playback blocked:', e);
        }
      });
    })();
  </script>
</body>
</html>
